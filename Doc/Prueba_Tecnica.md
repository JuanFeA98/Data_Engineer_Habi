## ğŸ  PRUEBA DATA ENGINEER HABI CO
___

**Importante:** Se recomienda leer todo el documento antes de empezar, en el momento en que usted reciba el correo de la prueba tendrÃ¡ (3 dÃ­as) para enviar el correo con las respuestas. Lo que busca esta prueba es evaluar su nivel de entendimiento desarrollando pipelines de datos capaces de ejecutarse en una nube como GCP y su capacidad para buscar documentaciÃ³n para la configuraciÃ³n de los servicios necesarios, asÃ­ como evaluar sus conocimientos con contenedores Docker. 

**âš’ï¸ PROBLEMA:**

Debe desarrollar un ETL en Python o Java que realice la lectura de un archivo XML (que fue proporcionado junto con este examen), lo transforme, extraiga caracterÃ­sticas y lo persista en una base de datos MySQL. La base de datos destino deberÃ¡ contener dos entidades: usuarios y propiedades debidamente relacionadas e indexadas. La ejecuciÃ³n del proceso debe hacerse dentro de un contenedor Docker que se conecte con la base de datos que de igual manera deberÃ¡ estar corriendo en un contenedor Docker. Se permite y se alienta el uso de un orquestador de contenedores.

**ğŸ“š Requisitos:**
Dividir el proceso en las siguientes etapas:
â—	Pre procesamiento y limpieza de datos del XML origen
â—	Pipeline de datos con salida hacia la base de datos
â—	Reporte de resultados de ejecuciÃ³n
â—	Debe contener documentaciÃ³n clara de cÃ³mo ejecutar el proyecto
â—	Debe ser entregado en un repositorio pÃºblico GIT del proveedor de su preferencia

Datos por extraer de los inmuebles:
1.	UbicaciÃ³n (estado, ciudad, colonia, calle y nÃºmero exterior)
2.	Tipo de inmueble
3.	TransacciÃ³n
4.	Precio
5.	CÃ³digo de proveedor
6.	Correo de contacto
7.	TelÃ©fono de contacto

Datos por extraer de los usuarios:
1.	Correo de contacto

**ğŸ  PREGUNTAS DE NEGOCIO:**

Cuando tenga el resultado hay que responder a las siguientes preguntas, incluyendo el query utilizado para generar la respuesta: 
1.	Â¿CuÃ¡ntos usuarios hay registrados?
2.	Â¿CuÃ¡ntas propiedades hay por cada usuario?
3.	Â¿CuÃ¡ntas casas y cuÃ¡ntos departamentos hay por estado?
4.	Â¿Tenemos cÃ³digos duplicados? Â¿Por quÃ©?

**ğŸš§ Bonus:**
Usa Apache Beam para implementar el pipeline de datos y Kubernetes como orquestador de contenedores.


**ğŸ“” Â¿CÃ³mo se evalÃºa?**

- **Funcionalidad:**
Se cumplen las 3 etapas de forma clara, concisa y abstraÃ­da. Se cumple con la carga de datos en MySQL y se pueden responder con queries las preguntas de negocio.
- **EjecuciÃ³n y orquestaciÃ³n:**
La ejecuciÃ³n estÃ¡ configurada para ser ejecutada en contenedores y correctamente orquestada.
- **Calidad del CÃ³digo:**
CÃ³digo bien estructurado y fÃ¡cil de mantener.
- **Manejo de Errores:**
El script maneja correctamente las excepciones y errores posibles.
- **DocumentaciÃ³n:**
DocumentaciÃ³n clara de toda la soluciÃ³n y de cÃ³mo ejecutar el pipeline en local.
- **Entrega en repositorio GIT:**
Se evaluarÃ¡ el correcto uso del repositorios de GIT. Mostrando conocimiento en manejo de branches, commits, comentarios, etc.
